# ğŸš€ Qwen2.5-Coder æƒ…æ„Ÿåˆ†æå¾®è°ƒæ•™ç¨‹

<div align="center">

[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IIIIQIIII/MSJ-Factory/blob/main/Qwen2_5_Sentiment_Fine_tuning_Tutorial.ipynb)
[![GitHub Stars](https://img.shields.io/github/stars/IIIIQIIII/MSJ-Factory?style=social)](https://github.com/IIIIQIIII/MSJ-Factory)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**æ‰‹æŠŠæ‰‹æ•™ä½ å¾®è°ƒ Qwen2.5-Coder è¿›è¡Œä¸­æ–‡æƒ…æ„Ÿåˆ†æ**

[English](README.md) | [ä¸­æ–‡](README_zh.md)

</div>

---

## ğŸ“– ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹)
- [ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ•™ç¨‹](#-ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ•™ç¨‹)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
  - [æ–¹å¼ä¸€ï¼šGoogle Colabï¼ˆæ¨èï¼‰](#æ–¹å¼ä¸€google-colabæ¨è)
  - [æ–¹å¼äºŒï¼šæœ¬åœ°è¿è¡Œ](#æ–¹å¼äºŒæœ¬åœ°è¿è¡Œ)
- [å®Œæ•´æ•™ç¨‹](#-å®Œæ•´æ•™ç¨‹)
  - [æ­¥éª¤1ï¼šå…‹éš†é¡¹ç›®](#æ­¥éª¤1å…‹éš†é¡¹ç›®ä»“åº“)
  - [æ­¥éª¤2ï¼šå®‰è£…ä¾èµ–](#æ­¥éª¤2å®‰è£…ä¾èµ–)
  - [æ­¥éª¤3ï¼šæ¨¡å‹å¾®è°ƒ](#æ­¥éª¤3æ¨¡å‹å¾®è°ƒ)
  - [æ­¥éª¤4ï¼šæ¨¡å‹è¯„ä¼°](#æ­¥éª¤4æ¨¡å‹è¯„ä¼°)
  - [æ­¥éª¤5ï¼šä¸Šä¼ åˆ°HuggingFace](#æ­¥éª¤5ä¸Šä¼ åˆ°huggingface)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [è®­ç»ƒé…ç½®](#-è®­ç»ƒé…ç½®)
- [è¯„ä¼°ç»“æœ](#-è¯„ä¼°ç»“æœ)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [å¼•ç”¨](#-å¼•ç”¨)
- [è‡´è°¢](#-è‡´è°¢)

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®ä½¿ç”¨**å†»ç»“è®­ç»ƒï¼ˆFreeze Trainingï¼‰**æ–¹æ³•å¾®è°ƒ **Qwen2.5-Coder-1.5B-Instruct** æ¨¡å‹ï¼Œç”¨äºä¸­æ–‡æƒ…æ„Ÿåˆ†æï¼š

- ğŸ¯ **ä»»åŠ¡**ï¼šäºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
- ğŸ“Š **æ•°æ®é›†**ï¼šChnSentiCorpï¼ˆä¸­æ–‡æƒ…æ„Ÿè¯­æ–™ï¼‰
- ğŸ”§ **æ–¹æ³•**ï¼šå†»ç»“è®­ç»ƒï¼ˆä»…è®­ç»ƒæœ€å6å±‚ï¼‰
- ğŸ’¾ **æ¨¡å‹å¤§å°**ï¼š15äº¿å‚æ•°
- â±ï¸ **è®­ç»ƒæ—¶é—´**ï¼šT4 GPU ä¸Š 15-30 åˆ†é’Ÿ
- ğŸ“ˆ **æ€§èƒ½æå‡**ï¼šå‡†ç¡®ç‡ä» **91.6%** æå‡åˆ° **97.8%**ï¼ˆ+6.2%ï¼‰

### ä»€ä¹ˆæ˜¯å†»ç»“è®­ç»ƒï¼Ÿ

å†»ç»“è®­ç»ƒæ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼š
- âœ… å†»ç»“å¤§éƒ¨åˆ†æ¨¡å‹å±‚
- âœ… åªè®­ç»ƒæœ€åå‡ å±‚ + è¯åµŒå…¥å±‚
- âœ… è®­ç»ƒæ—¶é—´å‡å°‘ 60-70%
- âœ… GPU æ˜¾å­˜å ç”¨å‡å°‘ 40-50%
- âœ… è¾¾åˆ°å®Œæ•´å¾®è°ƒ 85-95% çš„æ•ˆæœ

**é€‚ç”¨åœºæ™¯**ï¼šè®¡ç®—èµ„æºæœ‰é™ã€å¿«é€Ÿå®éªŒã€é¢†åŸŸé€‚é…

---

## âœ¨ ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ•™ç¨‹

### ğŸ“ æ–°æ‰‹å‹å¥½
- ğŸ“ é€æ­¥è¯¦è§£æ¯ä¸ªæ­¥éª¤
- ğŸ’¡ æ¯æ¡å‘½ä»¤éƒ½æœ‰è¯¦ç»†è¯´æ˜
- ğŸ› åŒ…å«å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- ğŸ“Š å¯è§†åŒ–è¿›åº¦æŒ‡ç¤ºå™¨

### ğŸš€ ç”Ÿäº§å°±ç»ª
- âš¡ é’ˆå¯¹ T4/A100 GPU ä¼˜åŒ–
- ğŸ“¦ å®Œæ•´çš„è¯„ä¼°æµç¨‹
- ğŸ”„ è‡ªåŠ¨æ¨¡å‹å¯¹æ¯”
- ğŸ“ˆ å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ï¼‰

### ğŸŒŸ ç°ä»£æŠ€æœ¯æ ˆ
- ğŸ¤– æœ€æ–°çš„ Qwen2.5-Coder æ¨¡å‹
- ğŸ”¥ LlamaFactory æ¡†æ¶é›†æˆ
- ğŸ“Š ä¸“ä¸šçš„è¯„ä¼°è„šæœ¬
- â˜ï¸ HuggingFace Hub é›†æˆ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šGoogle Colabï¼ˆæ¨èï¼‰

**é€‚åˆ**ï¼šåˆå­¦è€…ã€æ— éœ€æœ¬åœ° GPUã€å…è´¹ T4 GPU

1. ç‚¹å‡»é¡¶éƒ¨çš„ Colab å¾½ç« 
2. Runtime â†’ Change runtime type â†’ GPU (T4)
3. è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼ï¼ˆRuntime â†’ Run allï¼‰
4. ç­‰å¾… 30-40 åˆ†é’Ÿå®Œæˆæ•´ä¸ªæµç¨‹

**è¦æ±‚**ï¼šGoogle è´¦å·ï¼ˆå…è´¹ï¼‰

### æ–¹å¼äºŒï¼šæœ¬åœ°è¿è¡Œ

**é€‚åˆ**ï¼šæœ‰ç»éªŒçš„ç”¨æˆ·ã€å¤šæ¬¡è¿è¡Œã€è‡ªå®šä¹‰ä¿®æ”¹

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/IIIIQIIII/MSJ-Factory.git
cd MSJ-Factory

# å®‰è£…ä¾èµ–
pip install -e .[torch,bitsandbytes,vllm]

# å¼€å§‹è®­ç»ƒ
llamafactory-cli train examples/train_freeze/qwen2_5_coder_freeze_3k.yaml

# è¯„ä¼°æ¨¡å‹
python scripts/eval_sentiment_compare.py
```

**ç³»ç»Ÿè¦æ±‚**ï¼š
- Python 3.10+
- CUDA 11.8+ / 12.1+
- GPUï¼š16GB+ æ˜¾å­˜ï¼ˆT4ã€V100ã€A100 ç­‰ï¼‰
- ç£ç›˜ï¼š10GB å¯ç”¨ç©ºé—´

---

## ğŸ“š å®Œæ•´æ•™ç¨‹

### æ­¥éª¤1ï¼šå…‹éš†é¡¹ç›®ä»“åº“

**ä½œç”¨**ï¼šä¸‹è½½å®Œæ•´çš„é¡¹ç›®ä»£ç åˆ°ä½ çš„ç¯å¢ƒ

```bash
git clone --depth 1 https://github.com/IIIIQIIII/MSJ-Factory.git
cd MSJ-Factory
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Cloning into 'MSJ-Factory'...
remote: Enumerating objects: 368, done.
remote: Counting objects: 100% (368/368), done.
Receiving objects: 100% (368/368), 6.08 MiB | 11.88 MiB/s, done.
```

**éªŒè¯å®‰è£…**ï¼š
```bash
ls -lh
# ä½ åº”è¯¥çœ‹åˆ°ï¼šdata/ã€examples/ã€scripts/ã€src/ ç­‰ç›®å½•
```

<details>
<summary>ğŸ” ä»“åº“é‡Œæœ‰ä»€ä¹ˆï¼Ÿ</summary>

- `data/`ï¼šè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
- `examples/`ï¼šè®­ç»ƒé…ç½®æ–‡ä»¶
- `scripts/`ï¼šè¯„ä¼°å’Œå·¥å…·è„šæœ¬
- `src/`ï¼šæ ¸å¿ƒåº“ä»£ç 
- `contexts/`ï¼šæ–‡æ¡£å’ŒæŒ‡å—

</details>

---

### æ­¥éª¤2ï¼šå®‰è£…ä¾èµ–

**ä½œç”¨**ï¼šå®‰è£… PyTorchã€Transformersã€vLLM ç­‰å¿…éœ€åº“

```bash
pip install -e .[torch,bitsandbytes,vllm]
```

**å®‰è£…æ—¶é—´**ï¼š3-5 åˆ†é’Ÿ

**éªŒè¯å®‰è£…**ï¼š
```python
# æ£€æŸ¥ PyTorch
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

# æ£€æŸ¥ vLLM
python -c "import vllm; print(f'vLLM: {vllm.__version__}')"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
PyTorch: 2.5.0+cu121
CUDA: True
vLLM: 0.10.0
```

<details>
<summary>ğŸ› æ•…éšœæ’é™¤ï¼šå®‰è£…é—®é¢˜</summary>

**é—®é¢˜1ï¼šCUDA ä¸å¯ç”¨**
```bash
# å®‰è£…æ”¯æŒ CUDA çš„ PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**é—®é¢˜2ï¼šå®‰è£…æ—¶å†…å­˜ä¸è¶³**
```bash
# ä½¿ç”¨ --no-cache-dir
pip install --no-cache-dir -e .[torch,bitsandbytes,vllm]
```

**é—®é¢˜3ï¼švLLM å®‰è£…å¤±è´¥**
```bash
# è·³è¿‡ vLLMï¼ˆè®­ç»ƒæ—¶å¯é€‰ï¼‰
pip install -e .[torch,bitsandbytes]
```

</details>

---

### æ­¥éª¤3ï¼šæ¨¡å‹å¾®è°ƒ

**ä½œç”¨**ï¼šåœ¨ 3000 ä¸ªå¹³è¡¡çš„æƒ…æ„Ÿæ ·æœ¬ä¸Šå¾®è°ƒ Qwen2.5-Coder

#### 3.1 ç†è§£è®­ç»ƒé…ç½®

é…ç½®æ–‡ä»¶ï¼š`examples/train_freeze/qwen2_5_coder_freeze_3k.yaml`

```yaml
### æ¨¡å‹
model_name_or_path: Qwen/Qwen2.5-Coder-1.5B-Instruct  # åŸºç¡€æ¨¡å‹
trust_remote_code: true

### æ–¹æ³•
stage: sft                           # ç›‘ç£å¾®è°ƒ
finetuning_type: freeze             # å†»ç»“è®­ç»ƒæ–¹æ³•
freeze_trainable_layers: 6          # è®­ç»ƒæœ€å 6 å±‚
freeze_extra_modules: embed_tokens,norm

### æ•°æ®é›†
dataset: sentiment_balanced_3k       # 3000 æ ·æœ¬ï¼ˆ1500 æ­£ + 1500 è´Ÿï¼‰
template: qwen
cutoff_len: 720
max_samples: 10000

### è®­ç»ƒå‚æ•°
per_device_train_batch_size: 1      # æ¯ä¸ª GPU çš„æ‰¹æ¬¡å¤§å°
gradient_accumulation_steps: 8      # æœ‰æ•ˆæ‰¹æ¬¡ = 1 Ã— 8 = 8
learning_rate: 2.0e-5
num_train_epochs: 2.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true                          # ä½¿ç”¨ BF16 ç²¾åº¦

### è¯„ä¼°
val_size: 0.2                       # 20% éªŒè¯é›†
eval_strategy: steps
eval_steps: 200
compute_accuracy: true
```

#### 3.2 å¼€å§‹è®­ç»ƒ

```bash
llamafactory-cli train examples/train_freeze/qwen2_5_coder_freeze_3k.yaml
```

**è®­ç»ƒè¿›åº¦**ï¼š
```
ğŸš€ å¼€å§‹è®­ç»ƒ...
ğŸ“Š æ€»è½®æ•°ï¼š2
â±ï¸  é¢„è®¡æ—¶é—´ï¼š15-30 åˆ†é’Ÿ

Epoch 1/2:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% | Loss: 0.1234
Epoch 2/2:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% | Loss: 0.0567

âœ… è®­ç»ƒå®Œæˆï¼
ğŸ“ æ¨¡å‹ä¿å­˜è‡³ï¼šsaves/qwen2_5-coder-1.5b/freeze/sft/
```

#### 3.3 è®­ç»ƒæŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|--------|-------|
| æ€»æ­¥æ•° | ~375 æ­¥ |
| è®­ç»ƒæŸå¤± | 0.05 - 0.15 |
| éªŒè¯å‡†ç¡®ç‡ | 95%+ |
| GPU æ˜¾å­˜ | ~8-10 GB |
| è®­ç»ƒæ—¶é—´ | 15-30 åˆ†é’Ÿ |

<details>
<summary>ğŸ“Š ç†è§£è®­ç»ƒæ—¥å¿—</summary>

**å…³é”®æŒ‡æ ‡**ï¼š
- **Lossï¼ˆæŸå¤±ï¼‰**ï¼šåº”ä» ~0.5 é™è‡³ ~0.05
- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**ï¼šåº”æå‡è‡³ 95%+
- **GPU æ˜¾å­˜**ï¼šåœ¨ T4 ä¸Šåº”ä¿æŒåœ¨ 12GB ä»¥ä¸‹

**æ­£å¸¸ç°è±¡**ï¼š
- è®­ç»ƒåˆæœŸæŸå¤±å¯èƒ½æ³¢åŠ¨
- ç¬¬äºŒä¸ª epoch å‡†ç¡®ç‡æå‡
- ä¸€äº› TensorFlow è­¦å‘Šæ˜¯æ­£å¸¸çš„ï¼ˆå¯å¿½ç•¥ï¼‰

**è­¦å‘Šä¿¡å·**ï¼š
- æŸå¤±ä¸Šå‡æˆ–ä¿æŒåœ¨é«˜ä½ï¼ˆ>0.3ï¼‰
- è®­ç»ƒåå‡†ç¡®ç‡ä½äº 90%
- CUDA å†…å­˜æº¢å‡ºé”™è¯¯

</details>

<details>
<summary>ğŸ›ï¸ é«˜çº§ï¼šè‡ªå®šä¹‰è®­ç»ƒ</summary>

**è®­ç»ƒæ›´å¤šè½®æ¬¡**ï¼ˆæ›´å¥½çš„è´¨é‡ï¼‰ï¼š
```yaml
num_train_epochs: 3.0  # ä» 2.0 æ”¹ä¸º 3.0
```

**è®­ç»ƒæ›´å¤šå±‚**ï¼ˆæ›´å¤šé€‚é…ï¼‰ï¼š
```yaml
freeze_trainable_layers: 12  # ä» 6 æ”¹ä¸º 12
```

**ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡**ï¼ˆå¦‚æœæœ‰æ›´å¤šæ˜¾å­˜ï¼‰ï¼š
```yaml
per_device_train_batch_size: 2  # ä» 1 æ”¹ä¸º 2
gradient_accumulation_steps: 4  # ä» 8 æ”¹ä¸º 4
```

**è®­ç»ƒä¸åŒæ•°æ®é›†**ï¼š
```yaml
dataset: your_dataset_name  # å¿…é¡»åœ¨ data/dataset_info.json ä¸­æ³¨å†Œ
```

</details>

---

### æ­¥éª¤4ï¼šæ¨¡å‹è¯„ä¼°

**ä½œç”¨**ï¼šå¯¹æ¯”åŸºç¡€æ¨¡å‹ä¸å¾®è°ƒåæ¨¡å‹çš„æ€§èƒ½

```bash
python scripts/eval_sentiment_compare.py \
    --csv_path data/ChnSentiCorp_test.csv \
    --base_model Qwen/Qwen2.5-Coder-1.5B-Instruct \
    --finetuned_model saves/qwen2_5-coder-1.5b/freeze/sft \
    --output_file data/sentiment_comparison_results.json
```

**è¯„ä¼°æ—¶é—´**ï¼š5-10 åˆ†é’Ÿ

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸ“Š ChnSentiCorp æƒ…æ„Ÿåˆ†æ - å¾®è°ƒå‰åå¯¹æ¯”

======================================================================
ğŸ” è¯„ä¼°æ¨¡å‹ï¼šåŸºç¡€æ¨¡å‹ï¼ˆå¾®è°ƒå‰ï¼‰
======================================================================
æ€»æ ·æœ¬æ•°ï¼š179
å‡†ç¡®ç‡ï¼š91.62%
ç²¾ç¡®ç‡ï¼š98.57%
å¬å›ç‡ï¼š83.13%
F1åˆ†æ•°ï¼š90.20%

======================================================================
ğŸ” è¯„ä¼°æ¨¡å‹ï¼šå¾®è°ƒåæ¨¡å‹
======================================================================
æ€»æ ·æœ¬æ•°ï¼š179
å‡†ç¡®ç‡ï¼š97.77%
ç²¾ç¡®ç‡ï¼š100.00%
å¬å›ç‡ï¼š95.18%
F1åˆ†æ•°ï¼š97.53%

ğŸ¯ æ€§èƒ½å¯¹æ¯”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æŒ‡æ ‡          å¾®è°ƒå‰     å¾®è°ƒå      æå‡     æå‡ç‡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å‡†ç¡®ç‡        91.62%     97.77%  â†‘   6.15%      6.71%
ç²¾ç¡®ç‡        98.57%    100.00%  â†‘   1.43%      1.45%
å¬å›ç‡        83.13%     95.18%  â†‘  12.05%     14.50%
F1åˆ†æ•°        90.20%     97.53%  â†‘   7.33%      8.13%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³ï¼šdata/sentiment_comparison_results.json
```

#### 4.1 ç†è§£è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | ç›®æ ‡ |
|--------|---------------|--------|
| **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰** | æ•´ä½“æ­£ç¡®ç‡ | 95%+ |
| **ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰** | é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­å®é™…ä¸ºæ­£çš„æ¯”ä¾‹ | 95%+ |
| **å¬å›ç‡ï¼ˆRecallï¼‰** | å®é™…ä¸ºæ­£çš„æ ·æœ¬ä¸­è¢«æ­£ç¡®è¯†åˆ«çš„æ¯”ä¾‹ | 90%+ |
| **F1åˆ†æ•°ï¼ˆF1-Scoreï¼‰** | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | 95%+ |

#### 4.2 æ··æ·†çŸ©é˜µ

```
                é¢„æµ‹ä¸ºè´Ÿé¢          é¢„æµ‹ä¸ºæ­£é¢
å®é™…è´Ÿé¢         TN (91)              FP (5)
å®é™…æ­£é¢         FN (4)               TP (79)
```

- **çœŸè´Ÿä¾‹ï¼ˆTNï¼‰**ï¼š91 - æ­£ç¡®è¯†åˆ«çš„è´Ÿé¢æ ·æœ¬
- **å‡æ­£ä¾‹ï¼ˆFPï¼‰**ï¼š5 - è´Ÿé¢æ ·æœ¬è¢«é”™è¯¯åˆ†ç±»ä¸ºæ­£é¢
- **å‡è´Ÿä¾‹ï¼ˆFNï¼‰**ï¼š4 - æ­£é¢æ ·æœ¬è¢«é”™è¯¯åˆ†ç±»ä¸ºè´Ÿé¢
- **çœŸæ­£ä¾‹ï¼ˆTPï¼‰**ï¼š79 - æ­£ç¡®è¯†åˆ«çš„æ­£é¢æ ·æœ¬

<details>
<summary>ğŸ“ˆ åœ¨è‡ªå®šä¹‰æ–‡æœ¬ä¸Šå¿«é€Ÿæµ‹è¯•</summary>

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_sentiment.py`ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = "saves/qwen2_5-coder-1.5b/freeze/sft"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto")

text = "è¿™ä¸ªé…’åº—çš„æœåŠ¡æ€åº¦éå¸¸å¥½ï¼Œæˆ¿é—´ä¹Ÿå¾ˆå¹²å‡€ï¼"  # æ­£é¢ä¾‹å­

prompt = f"""è¯·å¯¹ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œåˆ¤æ–­å…¶æƒ…æ„Ÿå€¾å‘ã€‚

ä»»åŠ¡è¯´æ˜ï¼š
- åˆ†ææ–‡æœ¬è¡¨è¾¾çš„æ•´ä½“æƒ…æ„Ÿæ€åº¦
- åˆ¤æ–­æ˜¯æ­£é¢(1)è¿˜æ˜¯è´Ÿé¢(0)

æ–‡æœ¬å†…å®¹ï¼š
```sentence
{text}
```

è¾“å‡ºæ ¼å¼ï¼š
```json
{{
  "sentiment": 0 or 1
}}
```"""

messages = [{"role": "user", "content": prompt}]
text_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
model_inputs = tokenizer([text_input], return_tensors="pt").to(model.device)

generated_ids = model.generate(**model_inputs, max_new_tokens=256, temperature=0.1)
response = tokenizer.batch_decode(generated_ids[:, model_inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]

print(response)  # è¾“å‡ºï¼š{"sentiment": 1}
```

</details>

---

### æ­¥éª¤5ï¼šä¸Šä¼ åˆ°HuggingFace

**ä½œç”¨**ï¼šä¸ç¤¾åŒºåˆ†äº«ä½ çš„å¾®è°ƒæ¨¡å‹

#### 5.1 è·å– HuggingFace Token

1. è®¿é—® [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. ç‚¹å‡» "New token"
3. é€‰æ‹© "Write" æƒé™
4. å¤åˆ¶ tokenï¼ˆä»¥ `hf_` å¼€å¤´ï¼‰

#### 5.2 ä¸Šä¼ æ¨¡å‹

```python
from huggingface_hub import HfApi, login

# ç™»å½•
login(token="hf_YOUR_TOKEN_HERE")  # æ›¿æ¢ä¸ºä½ çš„ token

# ä¸Šä¼ 
api = HfApi()
api.create_repo(repo_id="YourUsername/Qwen2.5-Coder-Sentiment", private=False)

api.upload_folder(
    folder_path="saves/qwen2_5-coder-1.5b/freeze/sft",
    repo_id="YourUsername/Qwen2.5-Coder-Sentiment",
    commit_message="ä¸Šä¼ å†»ç»“è®­ç»ƒçš„ Qwen2.5-Coder æƒ…æ„Ÿåˆ†ææ¨¡å‹"
)

print("âœ… æ¨¡å‹å·²ä¸Šä¼ ï¼")
print("ğŸ”— https://huggingface.co/YourUsername/Qwen2.5-Coder-Sentiment")
```

#### 5.3 ä½¿ç”¨å·²ä¸Šä¼ çš„æ¨¡å‹

å…¶ä»–äººç°åœ¨å¯ä»¥ä½¿ç”¨ä½ çš„æ¨¡å‹ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("YourUsername/Qwen2.5-Coder-Sentiment")
tokenizer = AutoTokenizer.from_pretrained("YourUsername/Qwen2.5-Coder-Sentiment")
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
MSJ-Factory/
â”œâ”€â”€ data/                                    # æ•°æ®é›†
â”‚   â”œâ”€â”€ ChnSentiCorp_test.csv                # æµ‹è¯•æ•°æ®ï¼ˆ179 æ ·æœ¬ï¼‰
â”‚   â”œâ”€â”€ chnsenticorp_train_cleaned_instruct_balanced_3k.jsonl  # è®­ç»ƒæ•°æ®ï¼ˆ3000 æ ·æœ¬ï¼‰
â”‚   â””â”€â”€ dataset_info.json                    # æ•°æ®é›†æ³¨å†Œè¡¨
â”‚
â”œâ”€â”€ examples/                                # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ train_freeze/
â”‚       â””â”€â”€ qwen2_5_coder_freeze_3k.yaml     # ä¸»è¦è®­ç»ƒé…ç½®
â”‚
â”œâ”€â”€ scripts/                                 # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ eval_sentiment_compare.py            # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ convert_chnsenticorp.py              # æ•°æ®è½¬æ¢
â”‚
â”œâ”€â”€ contexts/                                # æ–‡æ¡£
â”‚   â”œâ”€â”€ chnsenticorp-evaluation-guide.md     # å®Œæ•´è¯„ä¼°æŒ‡å—
â”‚   â”œâ”€â”€ chnsenticorp-quick-reference.md      # å¿«é€Ÿå‘½ä»¤å‚è€ƒ
â”‚   â””â”€â”€ EVALUATION_SYSTEM_SUMMARY.md         # ç³»ç»Ÿæ¦‚è§ˆ
â”‚
â”œâ”€â”€ src/                                     # æ ¸å¿ƒåº“
â”‚   â””â”€â”€ llamafactory/                        # LlamaFactory é›†æˆ
â”‚
â”œâ”€â”€ saves/                                   # æ¨¡å‹è¾“å‡ºï¼ˆè®­ç»ƒæ—¶åˆ›å»ºï¼‰
â”‚   â””â”€â”€ qwen2_5-coder-1.5b/freeze/sft/       # å¾®è°ƒåçš„æ¨¡å‹
â”‚
â””â”€â”€ Qwen2_5_Sentiment_Fine_tuning_Tutorial.ipynb  # äº¤äº’å¼ notebook
```

---

## âš™ï¸ è®­ç»ƒé…ç½®

### æ¨èé…ç½®

#### T4 GPUï¼ˆ16GB æ˜¾å­˜ï¼‰
```yaml
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
freeze_trainable_layers: 6
bf16: true
```

#### A100 GPUï¼ˆ40GB æ˜¾å­˜ï¼‰
```yaml
per_device_train_batch_size: 4
gradient_accumulation_steps: 2
freeze_trainable_layers: 12  # è®­ç»ƒæ›´å¤šå±‚
bf16: true
```

#### å¤š GPU è®¾ç½®
```bash
# åŒå¡
CUDA_VISIBLE_DEVICES=0,1 llamafactory-cli train examples/train_freeze/qwen2_5_coder_freeze_3k.yaml

# å››å¡
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train examples/train_freeze/qwen2_5_coder_freeze_3k.yaml
```

### é…ç½®å‚æ•°è¯¦è§£

| å‚æ•° | å€¼ | ä½œç”¨ |
|-----------|-------|--------------|
| `freeze_trainable_layers` | 6 | è¦è®­ç»ƒçš„å±‚æ•°ï¼ˆä»æœ«å°¾ç®—èµ·ï¼‰ |
| `freeze_extra_modules` | embed_tokens,norm | é¢å¤–è®­ç»ƒçš„æ¨¡å— |
| `per_device_train_batch_size` | 1 | æ¯ä¸ª GPU æ¯æ­¥çš„æ ·æœ¬æ•° |
| `gradient_accumulation_steps` | 8 | ç´¯ç§¯æ¢¯åº¦ä»¥è·å¾—æ›´å¤§çš„æœ‰æ•ˆæ‰¹æ¬¡ |
| `learning_rate` | 2.0e-5 | æ¨¡å‹å­¦ä¹ çš„é€Ÿåº¦ |
| `num_train_epochs` | 2.0 | éå†æ•°æ®çš„æ¬¡æ•° |
| `bf16` | true | ä½¿ç”¨ BFloat16 åŠ é€Ÿè®­ç»ƒ |

---

## ğŸ“Š è¯„ä¼°ç»“æœ

### æ€§èƒ½æŒ‡æ ‡

| æ¨¡å‹ | å‡†ç¡®ç‡ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° |
|-------|----------|-----------|--------|----------|
| **åŸºç¡€æ¨¡å‹** | 91.62% | 98.57% | 83.13% | 90.20% |
| **å¾®è°ƒå** | **97.77%** â¬†ï¸ | **100.00%** â¬†ï¸ | **95.18%** â¬†ï¸ | **97.53%** â¬†ï¸ |
| **æå‡** | **+6.15%** | **+1.43%** | **+12.05%** | **+7.33%** |

### ä¸ºä»€ä¹ˆå¾®è°ƒæœ‰å¸®åŠ©

- âœ… **æ›´å¥½çš„é¢†åŸŸé€‚é…**ï¼šæ¨¡å‹å­¦ä¹ äº†ä¸­æ–‡æƒ…æ„Ÿè¡¨è¾¾æ¨¡å¼
- âœ… **æé«˜å¬å›ç‡**ï¼šæ•è·æ›´å¤šæ­£é¢æ¡ˆä¾‹ï¼ˆ83% â†’ 95%ï¼‰
- âœ… **å®Œç¾ç²¾ç¡®ç‡**ï¼šæ²¡æœ‰å‡æ­£ä¾‹ï¼ˆ98% â†’ 100%ï¼‰
- âœ… **ä¸€è‡´çš„é¢„æµ‹**ï¼šåœ¨è¾¹ç¼˜æ¡ˆä¾‹ä¸Šæ›´å¯é 

### çœŸå®æ¡ˆä¾‹

| æ–‡æœ¬ | åŸºç¡€æ¨¡å‹ | å¾®è°ƒå | æ­£ç¡® |
|------|------------|------------|---------|
| è¿™ä¸ªé…’åº—éå¸¸æ£’ï¼ | âœ… æ­£é¢ | âœ… æ­£é¢ | âœ… |
| æœåŠ¡æ€åº¦ä¸€èˆ¬èˆ¬ | âŒ æ­£é¢ | âœ… è´Ÿé¢ | âœ… |
| æˆ¿é—´è¿˜ç®—å¹²å‡€ | âŒ è´Ÿé¢ | âœ… æ­£é¢ | âœ… |
| ä»·æ ¼å¤ªè´µäº†ä¸å€¼ | âœ… è´Ÿé¢ | âœ… è´Ÿé¢ | âœ… |

---

## â“ å¸¸è§é—®é¢˜

<details>
<summary><b>Q1ï¼šéœ€è¦å¤šå°‘ GPU æ˜¾å­˜ï¼Ÿ</b></summary>

**æœ€ä½**ï¼š16GBï¼ˆT4ã€V100ï¼‰  
**æ¨è**ï¼š24GB+ï¼ˆA100ã€RTX 3090ï¼‰

å¯¹äº 16GB GPUï¼š
- ä½¿ç”¨ `bf16: true`
- ä¿æŒ `per_device_train_batch_size: 1`
- å¦‚éœ€è¦å¯å¢åŠ  `gradient_accumulation_steps`

</details>

<details>
<summary><b>Q2ï¼šå¯ä»¥åœ¨ CPU ä¸Šè®­ç»ƒå—ï¼Ÿ</b></summary>

**ä¸æ¨è**åœ¨ CPU ä¸Šè®­ç»ƒï¼Œå› ä¸ºï¼š
- æ¯” GPU æ…¢ 50-100 å€
- éœ€è¦ 12-24 å°æ—¶è€Œä¸æ˜¯ 15-30 åˆ†é’Ÿ

**æ›¿ä»£æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ Google Colabï¼ˆå…è´¹ T4 GPUï¼‰
- ä½¿ç”¨ Kaggle notebooksï¼ˆå…è´¹ P100 GPUï¼‰
- åœ¨ vast.ai æˆ– runpod.io ç§Ÿç”¨ GPU

</details>

<details>
<summary><b>Q3ï¼šå¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼Ÿ</b></summary>

**æ­¥éª¤1**ï¼šå‡†å¤‡ JSONL æ ¼å¼æ•°æ®
```json
{"messages": [
  {"role": "user", "content": "ä½ çš„æç¤ºè¯"},
  {"role": "assistant", "content": "æœŸæœ›çš„å›å¤"}
]}
```

**æ­¥éª¤2**ï¼šåœ¨ `data/dataset_info.json` ä¸­æ³¨å†Œ
```json
{
  "your_dataset": {
    "file_name": "your_data.jsonl",
    "formatting": "sharegpt",
    "columns": {"messages": "messages"}
  }
}
```

**æ­¥éª¤3**ï¼šæ›´æ–°è®­ç»ƒé…ç½®
```yaml
dataset: your_dataset  # åœ¨ YAML æ–‡ä»¶ä¸­ä¿®æ”¹
```

è¯¦è§ `contexts/dataset-formats-guide.md`ã€‚

</details>

<details>
<summary><b>Q4ï¼šè®­ç»ƒå¤±è´¥ï¼ŒCUDA OOM é”™è¯¯</b></summary>

**æ–¹æ¡ˆ1**ï¼šå‡å°‘æ‰¹æ¬¡å¤§å°
```yaml
per_device_train_batch_size: 1  # å·²ç»æ˜¯æœ€å°å€¼
gradient_accumulation_steps: 16  # å¢åŠ è¿™ä¸ª
```

**æ–¹æ¡ˆ2**ï¼šä½¿ç”¨ CPU å¸è½½ï¼ˆæ…¢ä½†æœ‰æ•ˆï¼‰
```yaml
deepspeed: examples/deepspeed/ds_z3_offload_config.json
```

**æ–¹æ¡ˆ3**ï¼šè®­ç»ƒæ›´å°‘çš„å±‚
```yaml
freeze_trainable_layers: 3  # ä» 6 å‡å°‘åˆ° 3
```

</details>

<details>
<summary><b>Q5ï¼šå¦‚ä½•è¿›ä¸€æ­¥æé«˜æ¨¡å‹æ€§èƒ½ï¼Ÿ</b></summary>

**é€‰é¡¹1**ï¼šè®­ç»ƒæ›´å¤šè½®æ¬¡
```yaml
num_train_epochs: 3.0  # æˆ– 4.0ã€5.0
```

**é€‰é¡¹2**ï¼šè®­ç»ƒæ›´å¤šå±‚
```yaml
freeze_trainable_layers: 12  # æ›´å¤šé€‚é…
```

**é€‰é¡¹3**ï¼šä½¿ç”¨å®Œæ•´å¾®è°ƒï¼ˆæ…¢å¾—å¤šï¼‰
```yaml
finetuning_type: full  # è€Œä¸æ˜¯ freeze
```

**é€‰é¡¹4**ï¼šæ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ®
- å½“å‰ï¼š3000 æ ·æœ¬
- æ¨èï¼š5000-10000 æ ·æœ¬ä»¥è·å¾—æœ€ä½³ç»“æœ

</details>

<details>
<summary><b>Q6ï¼šå¯ä»¥ç”¨äºè‹±æ–‡æƒ…æ„Ÿåˆ†æå—ï¼Ÿ</b></summary>

å¯ä»¥ï¼åªéœ€ï¼š
1. å‡†å¤‡è‹±æ–‡æƒ…æ„Ÿæ•°æ®é›†
2. æ›´æ–°æç¤ºè¯æ¨¡æ¿ï¼ˆåˆ é™¤ä¸­æ–‡ç‰¹å®šè¯´æ˜ï¼‰
3. æ³¨å†Œä½ çš„æ•°æ®é›†
4. ä½¿ç”¨ç›¸åŒé…ç½®è®­ç»ƒ

è¯¥æ¨¡å‹æ”¯æŒå¤šç§è¯­è¨€ã€‚

</details>

<details>
<summary><b>Q7ï¼šå¦‚ä½•éƒ¨ç½²æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Ÿ</b></summary>

**é€‰é¡¹1**ï¼šPython è„šæœ¬ï¼ˆæµ‹è¯•ç”¨ï¼‰
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("saves/qwen2_5-coder-1.5b/freeze/sft")
tokenizer = AutoTokenizer.from_pretrained("saves/qwen2_5-coder-1.5b/freeze/sft")

# ä½¿ç”¨ model.generate() è¿›è¡Œæ¨ç†
```

**é€‰é¡¹2**ï¼švLLMï¼ˆç”Ÿäº§ç”¨ï¼‰
```bash
vllm serve saves/qwen2_5-coder-1.5b/freeze/sft --port 8000
```

**é€‰é¡¹3**ï¼šLlamaFactory API
```bash
llamafactory-cli api examples/inference/qwen2_5_coder_sft.yaml
```

è¯¦è§ `contexts/chnsenticorp-evaluation-guide.md` ä¸­çš„éƒ¨ç½²æŒ‡å—ã€‚

</details>

---

## ğŸ“„ å¼•ç”¨

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{msj-factory-2025,
  title={Qwen2.5-Coder æƒ…æ„Ÿåˆ†æå¾®è°ƒæ•™ç¨‹},
  author={MSJ-Factory è´¡çŒ®è€…},
  year={2025},
  howpublished={\url{https://github.com/IIIIQIIII/MSJ-Factory}}
}
```

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ä¼˜ç§€çš„å¼€æºé¡¹ç›®ï¼š

- **[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)** - é«˜æ•ˆçš„å¾®è°ƒæ¡†æ¶
- **[Qwen2.5](https://github.com/QwenLM/Qwen2.5)** - å¼ºå¤§çš„åŸºç¡€æ¨¡å‹
- **[Transformers](https://github.com/huggingface/transformers)** - HuggingFace åº“
- **[vLLM](https://github.com/vllm-project/vllm)** - å¿«é€Ÿæ¨ç†å¼•æ“

ç‰¹åˆ«æ„Ÿè°¢ï¼š
- é˜¿é‡Œå·´å·´äº‘å‘å¸ƒ Qwen2.5 æ¨¡å‹
- HuggingFace æä¾›æ¨¡å‹æ‰˜ç®¡
- Google Colab æä¾›å…è´¹ GPU è®¿é—®

---

## â­ æ”¯æŒæœ¬é¡¹ç›®

å¦‚æœè¿™ä¸ªæ•™ç¨‹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ï¼š

1. **â­ ç»™æœ¬ä»“åº“ç‚¹ä¸ª Star** - å¸®åŠ©å…¶ä»–äººå‘ç°è¿™ä¸ªé¡¹ç›®
2. **ğŸ”— åˆ†äº«** - å‘Šè¯‰ä½ çš„æœ‹å‹å’ŒåŒäº‹
3. **ğŸ› æŠ¥å‘Šé—®é¢˜** - å¸®åŠ©æˆ‘ä»¬æ”¹è¿›
4. **ğŸ“ è´¡çŒ®ä»£ç ** - æ¬¢è¿ Pull Requestï¼

**ğŸ‘‰ åˆ«å¿˜äº†ç‚¹ Starï¼è¿™å¯¹æˆ‘ä»¬æ„ä¹‰é‡å¤§ï¼â­**

[![Star History Chart](https://api.star-history.com/svg?repos=IIIIQIIII/MSJ-Factory&type=Date)](https://star-history.com/#IIIIQIIII/MSJ-Factory&Date)

---

<div align="center">

**ç”¨ â¤ï¸ æ„å»º by MSJ-Factory å›¢é˜Ÿ**

[ğŸŒŸ Star](https://github.com/IIIIQIIII/MSJ-Factory) Â· [ğŸ› Issues](https://github.com/IIIIQIIII/MSJ-Factory/issues) Â· [ğŸ“– æ–‡æ¡£](https://github.com/IIIIQIIII/MSJ-Factory/tree/main/contexts)

</div>

